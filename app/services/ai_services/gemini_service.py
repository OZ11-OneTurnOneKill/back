import json
from google import generativeai as genai
from typing import Dict, Any, Optional, List
from datetime import datetime
from app.dtos.ai.study_plan import StudyPlanRequest

import logging
import json
import re

logger = logging.getLogger(__name__)


class GeminiService:
    """Gemini API ì—°ë™ ì„œë¹„ìŠ¤ - ì™„ì „ ë²”ìš© í•™ìŠµê³„íš ìƒì„±ê¸°"""

    def __init__(self, api_key: str):
        """Gemini ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.api_key = api_key
        genai.configure(api_key=api_key)

        generation_config = genai.types.GenerationConfig(
            max_output_tokens=2048,
            temperature=0.3,
            top_p=0.8,
            top_k=40
        )

        self.model = genai.GenerativeModel(
            'gemini-2.5-flash',
            generation_config=generation_config
        )

        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
        ]
        self.safety_settings = safety_settings

    def _extract_text_from_response(self, response) -> str:
        """Gemini ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            if hasattr(response, 'text') and response.text:
                return response.text
        except Exception as e:
            logger.warning(f"âš ï¸ response.text ì ‘ê·¼ ì‹¤íŒ¨: {e}")

        try:
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'content') and candidate.content:
                    if hasattr(candidate.content, 'parts') and candidate.content.parts:
                        text_parts = []
                        for part in candidate.content.parts:
                            if hasattr(part, 'text') and part.text:
                                text_parts.append(part.text)
                        if text_parts:
                            return ''.join(text_parts)
        except Exception as e:
            logger.warning(f"âš ï¸ candidates ì ‘ê·¼ ì‹¤íŒ¨: {e}")

        logger.error("âŒ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ì‹¤íŒ¨")
        return "ë¹ˆ ì‘ë‹µ"

    async def generate_study_plan(self, request) -> Dict[str, Any]:
        """ì™„ì „ ë²”ìš© í•™ìŠµê³„íš ìƒì„± ì‹œìŠ¤í…œ"""
        try:
            logger.info(f"ğŸ” API í‚¤ í™•ì¸: {self.api_key[:10]}..." if self.api_key else "âŒ API í‚¤ ì—†ìŒ")

            prompt = self._build_universal_prompt(request)
            logger.info(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: {len(prompt)} ë¬¸ì")

            # Gemini API í˜¸ì¶œ
            response = await self.model.generate_content_async(prompt)
            response_text = self._extract_text_from_response(response)
            logger.info(f"ğŸ“„ ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ: {len(response_text)} ë¬¸ì")

            # JSON íŒŒì‹± ì‹œë„
            try:
                clean_text = self._clean_json_response(response_text)
                parsed_response = json.loads(clean_text)
                logger.info("âœ… JSON íŒŒì‹± ì„±ê³µ!")
                return parsed_response

            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                return self._generate_intelligent_fallback_plan(request, response_text)

        except Exception as e:
            logger.error(f"âŒ Gemini API í˜¸ì¶œ ì „ì²´ ì‹¤íŒ¨: {e}")
            return self._generate_intelligent_fallback_plan(request, str(e))

    def _clean_json_response(self, response_text: str) -> str:
        """JSON ì‘ë‹µ ì •ë¦¬"""
        clean_text = response_text.strip()

        if clean_text.startswith("```json"):
            start_index = clean_text.find('\n') + 1
            end_index = clean_text.rfind("```")
            if end_index > start_index:
                clean_text = clean_text[start_index:end_index]
            else:
                clean_text = clean_text[7:]
        elif clean_text.startswith("```"):
            start_index = clean_text.find('\n') + 1
            end_index = clean_text.rfind("```")
            if end_index > start_index:
                clean_text = clean_text[start_index:end_index]
            else:
                clean_text = clean_text[3:]

        return clean_text.strip()

    def _build_universal_prompt(self, request: StudyPlanRequest) -> str:
        """ì™„ì „ ë²”ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° - ì–´ë–¤ ë¶„ì•¼ë“  ëŒ€ì‘"""

        duration_days = (request.end_date - request.start_date).days
        duration_weeks = max(1, duration_days // 7)

        # ì‚¬ìš©ì ì…ë ¥ ë¶„ì„
        subject_analysis = self._analyze_user_input(request.input_data)
        duration_info = self._get_duration_characteristics(duration_weeks)
        challenge_instruction = self._get_challenge_instruction(request.is_challenge, duration_weeks)

        prompt = f"""
ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³ ì˜ êµìœ¡ ì„¤ê³„ ì „ë¬¸ê°€ì´ì í•™ìŠµ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ìš”ì²­í•œ "{request.input_data}"ì— ëŒ€í•œ {duration_weeks}ì£¼ê°„ í•™ìŠµê³„íšì„ ì„¤ê³„í•´ì£¼ì„¸ìš”.

{challenge_instruction}

**ì‚¬ìš©ì ìš”ì²­ ë¶„ì„:**
- í•™ìŠµ ì£¼ì œ: {request.input_data}
- í•™ìŠµ ê¸°ê°„: {duration_days}ì¼ ({duration_weeks}ì£¼)
- ëª©í‘œ í‚¤ì›Œë“œ: {subject_analysis['keywords']}
- í•™ìŠµ ëª©ì : {subject_analysis['purpose']}
- ì˜ˆìƒ ë‚œì´ë„: {duration_info['difficulty']}
- ê¶Œì¥ í•™ìŠµì‹œê°„: {duration_info['recommended_hours']}ì‹œê°„

**ì„¤ê³„ ì² í•™:**
1. **ì ì‘ì„±**: ì–´ë–¤ ë¶„ì•¼ë“  ì²´ê³„ì ìœ¼ë¡œ ì ‘ê·¼
2. **ì‹¤ìš©ì„±**: ì‹¤ì œ ìƒí™œì´ë‚˜ ì—…ë¬´ì— ë°”ë¡œ ì ìš© ê°€ëŠ¥
3. **ì§„í–‰ì„±**: ê¸°ì´ˆ â†’ ì¤‘ê¸‰ â†’ ê³ ê¸‰ â†’ ë§ˆìŠ¤í„° ë‹¨ê³„ì  ë°œì „
4. **êµ¬ì²´ì„±**: ì¶”ìƒì  í‘œí˜„ ê¸ˆì§€, ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ë‚´ìš©
5. **ê²€ì¦ì„±**: í•™ìŠµ ì„±ê³¼ë¥¼ ì¸¡ì •í•  ìˆ˜ ìˆëŠ” ëª…í™•í•œ ê¸°ì¤€

**í•™ìŠµ ë‹¨ê³„ ì„¤ê³„ ì›ì¹™:**
- 1ë‹¨ê³„ (ê¸°ì´ˆ): ê°œë… ì´í•´ + ê¸°ë³¸ ë„êµ¬/ë°©ë²• ìŠµë“
- 2ë‹¨ê³„ (ì‘ìš©): ì‹¤ë¬´ ê¸°ë²• + ì‹¤ìŠµ í”„ë¡œì íŠ¸ ìˆ˜í–‰  
- 3ë‹¨ê³„ (ì‹¬í™”): ê³ ê¸‰ ê¸°ë²• + ì°½ì˜ì  ì‘ìš©
- 4ë‹¨ê³„ (ì™„ì„±): ì „ë¬¸ì„± êµ¬ì¶• + ì‹¤ì „ ì ìš©

**í•„ìˆ˜ í¬í•¨ ìš”ì†Œ:**
- {duration_weeks}ì£¼ ì „ì²´ ìƒì„¸ ê³„íš
- ë§¤ì£¼ 7ì¼ê°„ êµ¬ì²´ì  ì¼ë³„ ëª©í‘œ
- ì‹¤ìŠµí•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ê³¼ì œ
- í•™ìŠµ ì„±ê³¼ ì¸¡ì • ë°©ë²•
- ì¶”ì²œ í•™ìŠµ ìë£Œì™€ ë„êµ¬
- ì‹¤ì „ í™œìš© íŒ

**JSON ì‘ë‹µ í˜•ì‹:**
```json
{{
    "title": "{duration_weeks}ì£¼ ì™„ì „ ë§ˆìŠ¤í„° ê³¼ì •",
    "total_weeks": {duration_weeks},
    "difficulty": "{duration_info['difficulty']}",
    "estimated_total_hours": {duration_info['recommended_hours']},
    "description": "ì´ ê³¼ì •ì„ í†µí•´ ë‹¬ì„±í•  ìˆ˜ ìˆëŠ” ìµœì¢… ëª©í‘œì™€ í•µì‹¬ ê°€ì¹˜",
    "weekly_plans": [
        {{
            "week": 1,
            "title": "1ì£¼ì°¨: ê¸°ì´ˆ ì™„ì„±",
            "theme": "Foundation Building",
            "topics": ["ê¸°ë³¸ ê°œë…", "ë„êµ¬ ì‚¬ìš©ë²•", "ê¸°ì´ˆ ì‹¤ìŠµ"],
            "daily_goals": [
                "1ì¼: ê°œìš” íŒŒì•… ë° í™˜ê²½ êµ¬ì„±",
                "2ì¼: í•µì‹¬ ê°œë… ì´í•´",
                "3ì¼: ê¸°ì´ˆ ë„êµ¬ ì‚¬ìš©ë²•",
                "4ì¼: ê°„ë‹¨í•œ ì‹¤ìŠµ",
                "5ì¼: ê¸°ì´ˆ ì´ë¡  ì ìš©",
                "6ì¼: ë¯¸ë‹ˆ í”„ë¡œì íŠ¸",
                "7ì¼: ë³µìŠµ ë° ì •ë¦¬"
            ],
            "goals": ["ê¸°ë³¸ ê°œë… ì´í•´", "ê¸°ì´ˆ ì‹¤ìŠµ ì™„ë£Œ"],
            "assignments": ["ê¸°ì´ˆ ê³¼ì œ", "ì‹¤ìŠµ í”„ë¡œì íŠ¸"],
            "estimated_hours": {int(duration_info['recommended_hours'] / duration_weeks)},
            "difficulty_level": "beginner"
        }}
    ],
    "milestones": [
        {{
            "week": {max(1, duration_weeks // 4)},
            "milestone": "ê¸°ì´ˆ ì™„ì„±",
            "verification_method": "ê¸°ë³¸ í…ŒìŠ¤íŠ¸ í†µê³¼"
        }}
    ],
    "resources": [
        {{
            "type": "essential",
            "title": "ê¸°ì´ˆ í•™ìŠµ ìë£Œ",
            "url": "ê´€ë ¨ ì‚¬ì´íŠ¸ ë˜ëŠ” êµì¬",
            "priority": "high"
        }}
    ],
    "tips": [
        "ë§¤ì¼ ê¾¸ì¤€í•œ í•™ìŠµ",
        "ì´ë¡ ê³¼ ì‹¤ìŠµì˜ ê· í˜•",
        "ì–´ë ¤ìš´ ë¶€ë¶„ ë°˜ë³µ í•™ìŠµ"
    ]
}}
```

**ì¤‘ìš” ì§€ì¹¨:**
- ë°˜ë“œì‹œ ì™„ë²½í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ
- {duration_weeks}ì£¼ ì „ì²´ ê³„íšì„ ìƒì„¸íˆ ì‘ì„±
- ê° ì£¼ë§ˆë‹¤ 7ì¼ê°„ì˜ êµ¬ì²´ì ì¸ daily_goals ì œê³µ
- ì‹¤í˜„ ê°€ëŠ¥í•˜ê³  ì¸¡ì • ê°€ëŠ¥í•œ ëª©í‘œ ì„¤ì •

ì§€ê¸ˆ ë°”ë¡œ "{request.input_data}" ë¶„ì•¼ì˜ ìµœê³  í’ˆì§ˆ {duration_weeks}ì£¼ í•™ìŠµê³„íšì„ JSONìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
        return prompt

    def _analyze_user_input(self, input_text: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì…ë ¥ ì§€ëŠ¥ì  ë¶„ì„ - ì–´ë–¤ ë¶„ì•¼ë“  ë¶„ì„"""

        # ğŸ”¥ í•µì‹¬ ì£¼ì œ ì¶”ì¶œ (ê¸¸ì´ ì œí•œ)
        core_subject = self._extract_core_subject(input_text)

        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        words = input_text.lower().split()

        # í‚¤ì›Œë“œ ì¶”ì¶œ (ì¡°ì‚¬, ì „ì¹˜ì‚¬ ë“± ì œê±°)
        stop_words = ['ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ë¡œ', 'ì™€', 'ê³¼', 'ì˜', 'ì€', 'ëŠ”',
                      'í•˜ê³ ', 'í•˜ëŠ”', 'í•˜ê¸°', 'ì—ëŒ€í•´', 'ì— ëŒ€í•´', 'ê³µë¶€', 'í•™ìŠµ', 'ë°°ìš°', 'ìµíˆ',
                      'ë‚˜ëŠ”', 'ë‚´ê°€', 'ì €ëŠ”', 'ì œê°€', 'í•˜ë£¨ì—', 'ì‹œê°„ì”©', 'íˆ¬ì', 'ê°€ëŠ¥í•˜ê³ ', 'í¬í•¨í•´ì¤˜',
                      'ì£¼ê³ ', 'ë§Œë“¤ì–´ì¤˜', 'ì¶”ê°€í•´ì£¼ê³ ', 'í•˜ê³ ì‹¶ì–´', 'ì‹¶ì–´', 'ì›í•´', 'ë°”ë˜']
        keywords = [word for word in words if word not in stop_words and len(word) > 1]

        # í•™ìŠµ ëª©ì  ì¶”ë¡ 
        purpose = self._infer_learning_purpose(input_text)

        # ë¶„ì•¼ ìœ í˜• ì¶”ë¡ 
        field_type = self._infer_field_type(input_text, keywords)

        # í•™ìŠµ ì ‘ê·¼ë²• ì¶”ë¡ 
        approach = self._infer_learning_approach(field_type)

        # í•µì‹¬ ìŠ¤í‚¬ ì¶”ë¡ 
        skills = self._infer_key_skills(keywords, field_type)

        # ì‹¤ìš©ì  í™œìš©ë²• ì¶”ë¡ 
        applications = self._infer_practical_applications(keywords, field_type)

        return {
            "core_subject": core_subject,  # ğŸ”¥ ì¶”ê°€: í•µì‹¬ ì£¼ì œ
            "keywords": keywords[:5],  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ
            "purpose": purpose,
            "field_type": field_type,
            "approach": approach,
            "skills": skills,
            "applications": applications
        }

    def _extract_core_subject(self, input_text: str) -> str:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ í•µì‹¬ ì£¼ì œë§Œ ì¶”ì¶œ (ì™„ì „ ë²”ìš©)"""

        # ë¶ˆí•„ìš”í•œ ë¬¸êµ¬ë“¤ ì œê±°
        noise_phrases = [
            'ë‚˜ëŠ”', 'ì €ëŠ”', 'ë‚´ê°€', 'ì œê°€', 'ìš°ë¦¬ëŠ”', 'ìš°ë¦¬ê°€',
            'í•˜ê³  ì‹¶ì–´', 'í•˜ê³ ì‹¶ì–´', 'ì›í•´', 'ë°”ë˜', 'í•˜ë ¤ê³ ',
            'ê³µë¶€í•˜ê³ ', 'ë°°ìš°ê³ ', 'ìµíˆê³ ', 'í•™ìŠµí•˜ê³ ', 'ë§ˆìŠ¤í„°í•˜ê³ ',
            'ì§‘ì¤‘ì ìœ¼ë¡œ', 'ì²´ê³„ì ìœ¼ë¡œ', 'ê¼¼ê¼¼íˆ', 'ì™„ì „íˆ',
            'ê¸°ê°„ ë™ì•ˆ', 'ì‹œê°„ ë™ì•ˆ', 'ì‹œê°„ì”©', 'íˆ¬ì ê°€ëŠ¥í•˜ê³ ',
            'í¬í•¨í•´ì¤˜', 'ì£¼ê³ ', 'ë§Œë“¤ì–´ì¤˜', 'ì¶”ê°€í•´ì£¼ê³ ', 'í•˜ê³  ì‹¶ì–´'
        ]

        # ì…ë ¥ í…ìŠ¤íŠ¸ ì •ë¦¬
        cleaned_text = input_text
        for phrase in noise_phrases:
            cleaned_text = cleaned_text.replace(phrase, ' ')

        # ì—°ì† ê³µë°± ì œê±°
        cleaned_text = ' '.join(cleaned_text.split())

        # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ì²« ë²ˆì§¸ ë¬¸ì¥ì—ì„œ)
        sentences = cleaned_text.split('.')
        if sentences:
            first_sentence = sentences[0].strip()

            # ì¡°ì‚¬, ì „ì¹˜ì‚¬ ë“± ì œê±°
            words = first_sentence.split()
            meaningful_words = []

            for word in words:
                # ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ë§Œ ì„ íƒ (2ê¸€ì ì´ìƒ, ìˆ«ìë‚˜ íŠ¹ìˆ˜ë¬¸ì í¬í•¨ X)
                if (len(word) >= 2 and
                        not word.isdigit() and
                        word not in ['ë™ì•ˆ', 'ê¹Œì§€', 'ë¶€í„°', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ì—ê²Œ']):
                    meaningful_words.append(word)

            # ì²˜ìŒ 1-2ê°œ ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ë¡œ ì£¼ì œ êµ¬ì„±
            if meaningful_words:
                if len(meaningful_words) == 1:
                    return meaningful_words[0]
                elif len(meaningful_words) >= 2:
                    # ë‘ ë‹¨ì–´ ì¡°í•©ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” ì£¼ì œ ë§Œë“¤ê¸°
                    return ' '.join(meaningful_words[:2])

        # ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
        return "ë§ì¶¤í˜• í•™ìŠµ"

    def _infer_learning_purpose(self, input_text: str) -> str:
        """í•™ìŠµ ëª©ì  ì¶”ë¡ """
        input_lower = input_text.lower()

        if any(word in input_lower for word in ['ì·¨ì—…', 'ë©´ì ‘', 'ì´ì§', 'ì»¤ë¦¬ì–´']):
            return "ì·¨ì—…/ì»¤ë¦¬ì–´ ì¤€ë¹„"
        elif any(word in input_lower for word in ['ì‹œí—˜', 'ìê²©ì¦', 'ì¸ì¦', 'ì ìˆ˜']):
            return "ì‹œí—˜/ìê²©ì¦ ì·¨ë“"
        elif any(word in input_lower for word in ['ì·¨ë¯¸', 'ì—¬ê°€', 'ì¦ê±°ì›€', 'ì¬ë¯¸']):
            return "ì·¨ë¯¸/ê°œì¸ ë°œì „"
        elif any(word in input_lower for word in ['ì—…ë¬´', 'ì§ë¬´', 'ì‹¤ë¬´', 'íšŒì‚¬']):
            return "ì—…ë¬´ ì—­ëŸ‰ ê°•í™”"
        elif any(word in input_lower for word in ['ì°½ì—…', 'ì‚¬ì—…', 'ë¹„ì¦ˆë‹ˆìŠ¤']):
            return "ì°½ì—…/ì‚¬ì—… ì¤€ë¹„"
        else:
            return "ì „ë¬¸ì„± ê°œë°œ ë° ì—­ëŸ‰ ê°•í™”"

    def _infer_field_type(self, input_text: str, keywords: List[str]) -> str:
        """ë¶„ì•¼ ìœ í˜• ë²”ìš© ì¶”ë¡ """
        input_lower = input_text.lower()

        # í•™ìŠµ ë°©ì‹ì— ë”°ë¥¸ ë¶„ë¥˜ (êµ¬ì²´ì  ê¸°ìˆ ë³´ë‹¤ëŠ” í•™ìŠµ íŠ¹ì„±ìœ¼ë¡œ ë¶„ë¥˜)
        if any(word in input_lower for word in ['í”„ë¡œê·¸ë˜ë°', 'ê°œë°œ', 'ì½”ë”©', 'ì»´í“¨í„°', 'ì†Œí”„íŠ¸ì›¨ì–´', 'it']):
            return "ê¸°ìˆ /ê°œë°œ"
        elif any(word in input_lower for word in ['ì–¸ì–´', 'íšŒí™”', 'ë²ˆì—­', 'í†µì—­', 'ì™¸êµ­ì–´']):
            return "ì–¸ì–´/ì†Œí†µ"
        elif any(word in input_lower for word in ['ì°½ì‘', 'ì˜ˆìˆ ', 'ë””ìì¸', 'ì‘í’ˆ', 'í‘œí˜„']):
            return "ì°½ì‘/ì˜ˆìˆ "
        elif any(word in input_lower for word in ['ì‚¬ì—…', 'ê²½ì˜', 'ë§ˆì¼€íŒ…', 'ê²½ì œ', 'ê¸ˆìœµ', 'íšŒê³„']):
            return "ë¹„ì¦ˆë‹ˆìŠ¤/ê²½ì˜"
        elif any(word in input_lower for word in ['ìš´ë™', 'ê±´ê°•', 'ìƒí™œ', 'ìš”ë¦¬', 'ì·¨ë¯¸']):
            return "ìƒí™œ/ì‹¤ìš©"
        elif any(word in input_lower for word in ['í•™ë¬¸', 'ì—°êµ¬', 'ì´ë¡ ', 'ê³¼í•™', 'ìˆ˜í•™', 'í•™ìŠµ']):
            return "í•™ë¬¸/ì—°êµ¬"
        elif any(word in input_lower for word in ['ìê²©ì¦', 'ì‹œí—˜', 'ì¸ì¦', 'í•©ê²©']):
            return "ìê²©/ì‹œí—˜"
        else:
            return "ì¼ë°˜/ê¸°íƒ€"

    def _infer_learning_approach(self, field_type: str) -> str:
        """í•™ìŠµ ì ‘ê·¼ë²• ë²”ìš© ì¶”ë¡ """
        approach_map = {
            "ê¸°ìˆ /ê°œë°œ": "ì´ë¡  í•™ìŠµ + ì‹¤ìŠµ ì¤‘ì‹¬ + í”„ë¡œì íŠ¸ ì™„ì„±",
            "ì–¸ì–´/ì†Œí†µ": "ë“£ê¸°, ë§í•˜ê¸°, ì½ê¸°, ì“°ê¸° 4ì˜ì—­ ê· í˜• í•™ìŠµ",
            "ì°½ì‘/ì˜ˆìˆ ": "ê¸°ì´ˆ ì´ë¡  + ì°½ì‘ ì‹¤ìŠµ + ì‘í’ˆ ì™„ì„±",
            "ë¹„ì¦ˆë‹ˆìŠ¤/ê²½ì˜": "ì´ë¡  í•™ìŠµ + ì‚¬ë¡€ ë¶„ì„ + ì‹¤ë¬´ ì ìš©",
            "í•™ë¬¸/ì—°êµ¬": "ê°œë… ì´í•´ + ë…¼ë¦¬ì  ì‚¬ê³  + ë¬¸ì œ í•´ê²°",
            "ìƒí™œ/ì‹¤ìš©": "ê¸°ì´ˆ ì´ë¡  + ì‹¤ì „ ì—°ìŠµ + ì‘ìš© í™œìš©",
            "ìê²©/ì‹œí—˜": "ì´ë¡  ì •ë¦¬ + ë¬¸ì œ í’€ì´ + ì‹¤ì „ ì‹œí—˜",
            "ì¼ë°˜/ê¸°íƒ€": "ì²´ê³„ì  ì´ë¡  í•™ìŠµ + ë‹¨ê³„ì  ì‹¤ë¬´ ì ìš©"
        }
        return approach_map.get(field_type, "ì²´ê³„ì  ì´ë¡  í•™ìŠµ + ì‹¤ë¬´ ì ìš©")

    def _infer_key_skills(self, keywords: List[str], field_type: str) -> List[str]:
        """í•µì‹¬ ìŠ¤í‚¬ ë²”ìš© ì¶”ë¡ """
        base_skills = {
            "ê¸°ìˆ /ê°œë°œ": ["ë…¼ë¦¬ì  ì‚¬ê³ ", "ë¬¸ì œ í•´ê²°", "ë„êµ¬ í™œìš©", "í”„ë¡œì íŠ¸ ì™„ì„±"],
            "ì–¸ì–´/ì†Œí†µ": ["ì˜ì‚¬ì†Œí†µ", "í‘œí˜„ ëŠ¥ë ¥", "ì´í•´ë ¥", "ë¬¸í™”ì  ì†Œì–‘"],
            "ì°½ì‘/ì˜ˆìˆ ": ["ì°½ì˜ì  í‘œí˜„", "ë¯¸ì  ê°ê°", "ê¸°ìˆ ì  ìˆ™ë ¨", "ì‘í’ˆ ì™„ì„±"],
            "ë¹„ì¦ˆë‹ˆìŠ¤/ê²½ì˜": ["ë¶„ì„ì  ì‚¬ê³ ", "ì „ëµ ê¸°íš", "ì˜ì‚¬ê²°ì •", "ì‹¤í–‰ë ¥"],
            "í•™ë¬¸/ì—°êµ¬": ["ì´ë¡ ì  ì´í•´", "ë…¼ë¦¬ì  ì‚¬ê³ ", "ì—°êµ¬ ë°©ë²•", "ë¹„íŒì  ë¶„ì„"],
            "ìƒí™œ/ì‹¤ìš©": ["ê¸°ë³¸ ê¸°ë²•", "ì‘ìš© ëŠ¥ë ¥", "ì‹¤ìƒí™œ ì ìš©", "ì§€ì†ì  ì‹¤ì²œ"],
            "ìê²©/ì‹œí—˜": ["ì´ë¡  ì •ë¦¬", "ë¬¸ì œ í•´ê²°", "ì‹œê°„ ê´€ë¦¬", "ì‹¤ì „ ëŒ€ì‘"],
            "ì¼ë°˜/ê¸°íƒ€": ["ê¸°ì´ˆ ì´í•´", "ì²´ê³„ì  ì‚¬ê³ ", "ì‹¤ë¬´ ì ìš©", "ì§€ì†ì  í•™ìŠµ"]
        }

        # í‚¤ì›Œë“œ ê¸°ë°˜ ë§ì¶¤ ìŠ¤í‚¬ ì¶”ê°€
        if keywords:
            custom_skills = [f"{keywords[0]} ì „ë¬¸ ì—­ëŸ‰"]
        else:
            custom_skills = ["ì „ë¬¸ ì§€ì‹ ìŠµë“"]

        return base_skills.get(field_type, ["ê¸°ì´ˆ ì´í•´", "ì‹¤ë¬´ ì ìš©", "ì „ë¬¸ì„± ê°œë°œ"]) + custom_skills

    def _infer_practical_applications(self, keywords: List[str], field_type: str) -> List[str]:
        """ì‹¤ìš©ì  í™œìš©ë²• ë²”ìš© ì¶”ë¡ """
        base_applications = {
            "ê¸°ìˆ /ê°œë°œ": ["ì—…ë¬´ íš¨ìœ¨í™”", "ê°œì¸ í”„ë¡œì íŠ¸", "í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì¶•", "ì»¤ë¦¬ì–´ ë°œì „"],
            "ì–¸ì–´/ì†Œí†µ": ["ì†Œí†µ ëŠ¥ë ¥ í–¥ìƒ", "ê¸€ë¡œë²Œ í™œë™", "ë¬¸í™” êµë¥˜", "ìê¸°ê³„ë°œ"],
            "ì°½ì‘/ì˜ˆìˆ ": ["ì‘í’ˆ í™œë™", "ê°œì¸ í‘œí˜„", "ì·¨ë¯¸ ìƒí™œ", "ë¶€ê°€ ìˆ˜ì…"],
            "ë¹„ì¦ˆë‹ˆìŠ¤/ê²½ì˜": ["ì—…ë¬´ ì—­ëŸ‰", "ì˜ì‚¬ê²°ì •", "ê²½ì˜ ëŠ¥ë ¥", "ì‚¬ì—… ê¸°íšŒ"],
            "í•™ë¬¸/ì—°êµ¬": ["ì§€ì‹ í™•ì¥", "ì—°êµ¬ í™œë™", "êµìœ¡ ëŠ¥ë ¥", "ì „ë¬¸ì„± ì¸ì •"],
            "ìƒí™œ/ì‹¤ìš©": ["ì¼ìƒ ê°œì„ ", "ê±´ê°• ê´€ë¦¬", "ì·¨ë¯¸ ìƒí™œ", "ì‚¶ì˜ ì§ˆ í–¥ìƒ"],
            "ìê²©/ì‹œí—˜": ["ìê²© ì·¨ë“", "ì·¨ì—… ì¤€ë¹„", "ìŠ¹ì§„ ê¸°íšŒ", "ì „ë¬¸ì„± ì¸ì¦"],
            "ì¼ë°˜/ê¸°íƒ€": ["ê°œì¸ ë°œì „", "ì‹¤ë¬´ í™œìš©", "ì „ë¬¸ì„± êµ¬ì¶•", "ë„¤íŠ¸ì›Œí‚¹"]
        }

        return base_applications.get(field_type, ["ê°œì¸ ë°œì „", "ì‹¤ë¬´ í™œìš©", "ì „ë¬¸ì„± êµ¬ì¶•"])

    def _get_duration_characteristics(self, weeks: int) -> Dict[str, Any]:
        """ê¸°ê°„ë³„ íŠ¹ì„± ë¶„ì„"""
        if weeks <= 1:
            return {
                "characteristics": "ì†ì„± ì…ë¬¸",
                "difficulty": "beginner",
                "recommended_hours": 8,
                "intensity": "ë§¤ìš° ë†’ìŒ"
            }
        elif weeks <= 4:
            return {
                "characteristics": "ì§‘ì¤‘ ê¸°ì´ˆ",
                "difficulty": "beginner_to_intermediate",
                "recommended_hours": weeks * 12,
                "intensity": "ë†’ìŒ"
            }
        elif weeks <= 8:
            return {
                "characteristics": "ì²´ê³„ì  í•™ìŠµ",
                "difficulty": "intermediate",
                "recommended_hours": weeks * 10,
                "intensity": "ë³´í†µ"
            }
        elif weeks <= 16:
            return {
                "characteristics": "ì‹¬í™” í•™ìŠµ",
                "difficulty": "intermediate_to_advanced",
                "recommended_hours": weeks * 8,
                "intensity": "ë³´í†µ"
            }
        else:
            return {
                "characteristics": "ì „ë¬¸ê°€ ê³¼ì •",
                "difficulty": "advanced",
                "recommended_hours": weeks * 6,
                "intensity": "ë‚®ìŒ"
            }

    def _get_challenge_instruction(self, is_challenge: bool, weeks: int) -> str:
        """ì±Œë¦°ì§€ ëª¨ë“œë³„ ì§€ì¹¨"""
        if is_challenge:
            return f"""
ğŸ”¥ **{weeks}ì£¼ ì§‘ì¤‘ ì±Œë¦°ì§€ ëª¨ë“œ** ğŸ”¥
- ê³ ê°•ë„ ëª°ì… í•™ìŠµìœ¼ë¡œ ìµœëŒ€ íš¨ê³¼ ë‹¬ì„±
- ë§¤ì¼ êµ¬ì²´ì ì´ê³  ë„ì „ì ì¸ ëª©í‘œ ì„¤ì •
- ì‹¤ìŠµê³¼ í”„ë¡œì íŠ¸ ì¤‘ì‹¬ì˜ ì²´í—˜ í•™ìŠµ
- ì£¼ì°¨ë³„ ëª…í™•í•œ ì„±ì·¨ ê¸°ì¤€ê³¼ ì¸ì¦ ë°©ë²•
- í¬ê¸°í•˜ì§€ ì•ŠëŠ” ê°•í•œ ì˜ì§€ë ¥ê³¼ ì§€ì†ì„± ìš”êµ¬
"""
        else:
            return f"""
ğŸ“š **{weeks}ì£¼ ì²´ê³„ì  í•™ìŠµ ëª¨ë“œ** ğŸ“š
- ê°œì¸ í˜ì´ìŠ¤ì— ë§ì¶˜ ì§€ì† ê°€ëŠ¥í•œ í•™ìŠµ
- ì´ë¡ ê³¼ ì‹¤ìŠµì˜ ê· í˜•ì¡íŒ ì»¤ë¦¬í˜ëŸ¼
- ë‹¨ê³„ì  ë‚œì´ë„ ìƒìŠ¹ê³¼ ì¶©ë¶„í•œ ë³µìŠµ
- ì•ˆì •ì  ê¸°ì´ˆ êµ¬ì¶•ê³¼ ì ì§„ì  ë°œì „
- ì¥ê¸°ì  ê´€ì ì˜ ê²¬ê³ í•œ ì‹¤ë ¥ ì™„ì„±
"""

    def _generate_intelligent_fallback_plan(self, request, error_info: str) -> Dict[str, Any]:
        """ì§€ëŠ¥í˜• ëŒ€ì²´ í•™ìŠµê³„íš ìƒì„±"""

        if request:
            input_text = request.input_data
            duration_days = (request.end_date - request.start_date).days
            duration_weeks = max(1, duration_days // 7)
            is_challenge = getattr(request, 'is_challenge', False)
        else:
            input_text = "ì¼ë°˜ í•™ìŠµ"
            duration_weeks = 4
            is_challenge = False

        # ì‚¬ìš©ì ì…ë ¥ ë¶„ì„
        analysis = self._analyze_user_input(input_text)
        duration_info = self._get_duration_characteristics(duration_weeks)

        # ì™„ì „í•œ í•™ìŠµê³„íš ë™ì  ìƒì„±
        return self._create_adaptive_study_plan(
            input_text, analysis, duration_weeks, duration_info, is_challenge, error_info
        )

    def _create_adaptive_study_plan(
            self,
            subject: str,
            analysis: Dict[str, Any],
            weeks: int,
            duration_info: Dict[str, Any],
            is_challenge: bool,
            error_info: str
    ) -> Dict[str, Any]:
        """ì™„ì „ ì ì‘í˜• í•™ìŠµê³„íš ìƒì„±"""

        mode = "ì§‘ì¤‘ ì±Œë¦°ì§€" if is_challenge else "ì²´ê³„ì  í•™ìŠµ"

        # ğŸ”¥ í•µì‹¬ ì£¼ì œ ì‚¬ìš© (ê¸¸ì´ ì œí•œëœ ê¹”ë”í•œ ì œëª©)
        core_subject = analysis.get('core_subject', 'Python')  # ê¸°ë³¸ê°’ì€ Python

        # ê¸°ë³¸ ê³„íš êµ¬ì¡°
        plan = {
            "title": f"{weeks}ì£¼ {core_subject} ì™„ì „ ë§ˆìŠ¤í„° {mode} ê³¼ì •",
            "total_weeks": weeks,
            "difficulty": duration_info['difficulty'],
            "estimated_total_hours": duration_info['recommended_hours'],
            "description": f"{core_subject} ë¶„ì•¼ì˜ {duration_info['characteristics']} í•™ìŠµì„ í†µí•´ {analysis['purpose']} ë‹¬ì„±",
            "subject_analysis": {
                "field_type": analysis['field_type'],
                "learning_approach": analysis['approach'],
                "key_skills": analysis['skills'],
                "practical_applications": analysis['applications']
            },
            "weekly_plans": [],
            "milestones": [],
            "resources": [],
            "tips": [
                "ë§¤ì¼ ê¾¸ì¤€í•œ í•™ìŠµì´ ì„±ê³µì˜ í•µì‹¬",
                "ì´ë¡ ê³¼ ì‹¤ìŠµì˜ ê· í˜•ì„ ë§ì¶”ì–´ ì§„í–‰",
                "ì‹¤íŒ¨ë¥¼ í•™ìŠµì˜ ê¸°íšŒë¡œ ë°›ì•„ë“¤ì´ê¸°",
                "ë™ë£Œë‚˜ ì „ë¬¸ê°€ì™€ ì ê·¹ì ìœ¼ë¡œ ì†Œí†µí•˜ê¸°"
            ],
            "success_factors": [
                "ì¼ê´€ëœ í•™ìŠµ ìŠµê´€ê³¼ íš¨ìœ¨ì  ì‹œê°„ ê´€ë¦¬",
                "ëŠ¥ë™ì ì¸ ì‹¤ìŠµê³¼ ì§€ì†ì ì¸ ë„ì „ ì •ì‹ ",
                "í”¼ë“œë°± ìˆ˜ìš©ê³¼ ì§€ì†ì ì¸ ê°œì„  ì˜ì§€",
                "ì‹¤ë¬´ ì ìš©ì„ ìœ„í•œ ì°½ì˜ì  ì‚¬ê³ ë ¥"
            ],
            "_fallback": True,
            "_source": "intelligent_adaptive_plan",
            "_core_subject": core_subject,  # ğŸ”¥ ì¶”ê°€: ë””ë²„ê¹…ìš©
            "_original_input": subject[:50] + "..." if len(subject) > 50 else subject,  # ğŸ”¥ ì¶”ê°€: ì›ë³¸ í™•ì¸ìš©
            "_analysis": analysis,
            "_error_info": error_info[:100] if error_info else "none"
        }

        # ì£¼ì°¨ë³„ ê³„íš ë™ì  ìƒì„± (í•µì‹¬ ì£¼ì œ ì‚¬ìš©)
        for week in range(1, weeks + 1):
            week_plan = self._generate_adaptive_week_plan(week, weeks, core_subject, analysis, duration_info)
            plan["weekly_plans"].append(week_plan)

        # ë§ˆì¼ìŠ¤í†¤ ë™ì  ìƒì„± (í•µì‹¬ ì£¼ì œ ì‚¬ìš©)
        plan["milestones"] = self._generate_adaptive_milestones(weeks, core_subject, analysis)

        # ìë£Œ ë™ì  ìƒì„± (í•µì‹¬ ì£¼ì œ ì‚¬ìš©)
        plan["resources"] = self._generate_adaptive_resources(core_subject, analysis)

        return plan

    def _generate_adaptive_week_plan(
            self,
            week: int,
            total_weeks: int,
            subject: str,
            analysis: Dict[str, Any],
            duration_info: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì ì‘í˜• ì£¼ì°¨ë³„ ê³„íš ìƒì„±"""

        # ì§„í–‰ë¥  ê¸°ë°˜ ë‹¨ê³„ ê²°ì •
        progress = week / total_weeks

        if progress <= 0.25:
            stage = "ê¸°ì´ˆ"
            stage_en = "Foundation"
            difficulty = "beginner"
            focus = "ê°œë… ì´í•´ì™€ ê¸°ë³¸ê¸° ë‹¤ì§€ê¸°"
        elif progress <= 0.5:
            stage = "ì‘ìš©"
            stage_en = "Application"
            difficulty = "intermediate"
            focus = "ì‹¤ë¬´ ê¸°ë²•ê³¼ ì‘ìš© ëŠ¥ë ¥"
        elif progress <= 0.75:
            stage = "ì‹¬í™”"
            stage_en = "Advanced"
            difficulty = "intermediate"
            focus = "ê³ ê¸‰ ê¸°ë²•ê³¼ ì „ë¬¸ì„±"
        else:
            stage = "ì™„ì„±"
            stage_en = "Mastery"
            difficulty = "advanced"
            focus = "í†µí•©ê³¼ ì‹¤ì „ ì ìš©"

        # ë¶„ì•¼ë³„ ë§ì¶¤ ì£¼ì œ ìƒì„±
        topics = self._generate_stage_topics(stage, subject, analysis)

        # ì¼ë³„ ëª©í‘œ ë™ì  ìƒì„±
        daily_goals = self._generate_daily_goals(week, stage, subject)

        # ëª©í‘œ ë° ê³¼ì œ ìƒì„± (ì™„ì „ ë²”ìš©)
        goals = [
            f"{subject} {stage} ë‹¨ê³„ í•µì‹¬ ê°œë… ì™„ì „ ì´í•´",
            f"{focus}ì„ í†µí•œ ì‹¤ë¬´ ì—­ëŸ‰ ê°œë°œ",
            f"ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰ì„ ìœ„í•œ ê²¬ê³ í•œ ê¸°ë°˜ êµ¬ì¶•"
        ]

        # ì™„ì „ ë²”ìš© ê³¼ì œ ìƒì„±
        assignments = [
            f"{stage} ìˆ˜ì¤€ì˜ {subject} ì‹¤ìŠµ ê³¼ì œ ì™„ì„±",
            f"{subject} ê´€ë ¨ ë¯¸ë‹ˆ í”„ë¡œì íŠ¸ ìˆ˜í–‰",
            f"{week}ì£¼ì°¨ í•™ìŠµ ì„±ê³¼ ì •ë¦¬ ë° ë°œí‘œ ì¤€ë¹„"
        ]

        return {
            "week": week,
            "title": f"{week}ì£¼ì°¨: {subject} {stage} ë§ˆìŠ¤í„°",
            "theme": f"{stage_en} & {focus}",
            "topics": topics,
            "daily_goals": daily_goals,
            "goals": goals,
            "assignments": assignments,
            "estimated_hours": duration_info['recommended_hours'] // total_weeks,
            "difficulty_level": difficulty
        }

    def _generate_stage_topics(self, stage: str, subject: str, analysis: Dict[str, Any]) -> List[str]:
        """ë‹¨ê³„ë³„ ì£¼ì œ ì™„ì „ ë²”ìš© ìƒì„±"""

        keywords = analysis.get('keywords', [])
        main_keyword = keywords[0] if keywords else subject

        if stage == "ê¸°ì´ˆ":
            return [
                f"{subject}ì˜ í•µì‹¬ ê°œë…ê³¼ ê¸°ë³¸ ìš©ì–´ ì •ë¦¬",
                f"í•™ìŠµì— í•„ìš”í•œ ë„êµ¬ì™€ í™˜ê²½ êµ¬ì„±",
                f"{main_keyword} ê¸°ì´ˆ ì´ë¡ ê³¼ ê¸°ë³¸ ì›ë¦¬",
                f"ê¸°ë³¸ ê¸°ë²•ê³¼ ë°©ë²•ë¡  ì´í•´",
                f"ê°„ë‹¨í•œ ì‹¤ìŠµì„ í†µí•œ ê¸°ì´ˆ ì ìš©",
                f"í•™ìŠµ ë°©í–¥ ì„¤ì •ê³¼ ê¸°ì´ˆ ë‹¤ì§€ê¸°"
            ]
        elif stage == "ì‘ìš©":
            return [
                f"{subject} ì¤‘ê¸‰ ê°œë…ê³¼ ì‹¤ë¬´ í™œìš©ë²•",
                f"íš¨ìœ¨ì ì¸ ì‘ì—… ë°©ë²•ê³¼ ë„êµ¬ ìˆ™ë ¨",
                f"ì‹¤ì „ ê¸°ë²•ê³¼ ì‘ìš© ë°©ë²•ë¡ ",
                f"ë¬¸ì œ í•´ê²° ì ‘ê·¼ë²•ê³¼ ì „ëµ",
                f"í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ê°œì„  ê¸°ë²•",
                f"ì‹¤ë¬´ ì‚¬ë¡€ ë¶„ì„ê³¼ ì ìš© ì—°ìŠµ"
            ]
        elif stage == "ì‹¬í™”":
            return [
                f"{subject} ê³ ê¸‰ ê¸°ë²•ê³¼ ì „ë¬¸ ì§€ì‹",
                f"ì°½ì˜ì  ì ‘ê·¼ë²•ê³¼ í˜ì‹ ì  ë°©ë²•",
                f"ë‹¤ì–‘í•œ ë¶„ì•¼ì™€ì˜ ì—°ê³„ í™œìš©",
                f"ìµœì‹  ë™í–¥ê³¼ ë°œì „ ë°©í–¥",
                f"ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ê²°ê³¼ë¬¼ ì°½ì¶œ",
                f"ë„¤íŠ¸ì›Œí‚¹ê³¼ ì§€ì‹ ê³µìœ  í™œë™"
            ]
        else:  # ì™„ì„±
            return [
                f"{subject} ì „ë¬¸ì„±ì˜ í†µí•©ê³¼ ì™„ì„±",
                f"ì‹¤ì „ ì ìš©ê³¼ ì„±ê³¼ ì¸¡ì • ë°©ë²•",
                f"ì§€ì†ì  ë°œì „ì„ ìœ„í•œ ì²´ê³„ êµ¬ì¶•",
                f"ì§€ì‹ ì „ë‹¬ê³¼ ë©˜í† ë§ ëŠ¥ë ¥",
                f"ì‹¤ë¬´ í™œìš©ê³¼ ê°€ì¹˜ ì°½ì¶œ ë°©ì•ˆ",
                f"í‰ìƒ í•™ìŠµê³¼ ì§€ì†ì  ì„±ì¥"
            ]

    def _generate_daily_goals(self, week: int, stage: str, subject: str) -> List[str]:
        """ì¼ë³„ ëª©í‘œ ì™„ì „ ë²”ìš© ìƒì„±"""

        return [
            f"1ì¼: {subject} {stage} ë‹¨ê³„ì˜ í•µì‹¬ ê°œë… í•™ìŠµ",
            f"2ì¼: ê¸°ë³¸ ë„êµ¬ì™€ ë°©ë²•ë¡  ì‹¤ìŠµ ì—°ìŠµ",
            f"3ì¼: í•™ìŠµ ë‚´ìš©ì˜ ì‹¤ì „ ì ìš© ì‹œë„",
            f"4ì¼: ì‘ìš© ê³¼ì œ ë˜ëŠ” í”„ë¡œì íŠ¸ ìˆ˜í–‰",
            f"5ì¼: ë³µìŠµê³¼ ì‹¬í™”ë¥¼ í†µí•œ ì™„ì „ ì´í•´",
            f"6ì¼: ì°½ì˜ì  í™œìš©ê³¼ í™•ì¥ í•™ìŠµ",
            f"7ì¼: {week}ì£¼ì°¨ ì„±ê³¼ ì •ë¦¬ ë° ë‹¤ìŒ ì¤€ë¹„"
        ]

    def _generate_adaptive_milestones(self, weeks: int, subject: str, analysis: Dict[str, Any]) -> List[Dict[str, str]]:
        """ì ì‘í˜• ë§ˆì¼ìŠ¤í†¤ ìƒì„±"""

        milestones = []

        # ê¸°ê°„ì— ë”°ë¥¸ ë§ˆì¼ìŠ¤í†¤ ì„¤ì •
        if weeks <= 4:
            milestone_weeks = [weeks]
            milestone_names = [f"{subject} ê¸°ì´ˆ ì™„ì„±"]
        elif weeks <= 8:
            milestone_weeks = [weeks // 2, weeks]
            milestone_names = [f"{subject} ê¸°ì´ˆ ì™„ì„±", f"{subject} ì‹¤ë¬´ í™œìš©"]
        else:
            milestone_weeks = [weeks // 4, weeks // 2, (weeks * 3) // 4, weeks]
            milestone_names = [
                f"{subject} ê¸°ì´ˆ ì™„ì„±",
                f"{subject} ì‘ìš© ëŠ¥ë ¥",
                f"{subject} ì‹¬í™” ì „ë¬¸ì„±",
                f"{subject} ë§ˆìŠ¤í„° ë‹¬ì„±"
            ]

        for week, name in zip(milestone_weeks, milestone_names):
            milestones.append({
                "week": week,
                "milestone": name,
                "verification_method": f"{name} í”„ë¡œì íŠ¸ ì™„ì„± ë° ì‹¤ë¬´ ì ìš© ì‹œì—°"
            })

        return milestones

    def _generate_adaptive_resources(self, subject: str, analysis: Dict[str, Any]) -> List[Dict[str, str]]:
        """ì ì‘í˜• í•™ìŠµ ìë£Œ ì™„ì „ ë²”ìš© ìƒì„±"""

        return [
            {
                "type": "essential",
                "title": f"{subject} ê¸°ì´ˆ í•™ìŠµ ìë£Œ",
                "url": f"{subject} ê´€ë ¨ ê¸°ë³¸ êµì¬ ë˜ëŠ” ì˜¨ë¼ì¸ ê°•ì˜",
                "priority": "high"
            },
            {
                "type": "practice",
                "title": f"{subject} ì‹¤ìŠµ í”Œë«í¼",
                "url": f"{subject} ì—°ìŠµì„ ìœ„í•œ ì˜¨ë¼ì¸ ë„êµ¬ë‚˜ ì‹¤ìŠµ ì‚¬ì´íŠ¸",
                "priority": "high"
            },
            {
                "type": "community",
                "title": f"{subject} í•™ìŠµ ì»¤ë®¤ë‹ˆí‹°",
                "url": f"{subject} ê´€ë ¨ ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹°ë‚˜ í•™ìŠµ ê·¸ë£¹",
                "priority": "medium"
            },
            {
                "type": "reference",
                "title": f"{subject} ì°¸ê³  ìë£Œ",
                "url": f"{subject} ê´€ë ¨ ì°¸ê³  ë¬¸ì„œë‚˜ ê°€ì´ë“œ",
                "priority": "medium"
            },
            {
                "type": "advanced",
                "title": f"{subject} ì‹¬í™” í•™ìŠµ",
                "url": f"{subject} ê³ ê¸‰ ê³¼ì •ì´ë‚˜ ì „ë¬¸ ìë£Œ",
                "priority": "low"
            }
        ]

    def _build_prompt(self, request: StudyPlanRequest) -> str:
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ (deprecated)"""
        return self._build_universal_prompt(request)

    async def generate_summary(
            self,
            content: str,
            summary_type: str = "general",
            title: Optional[str] = None
    ) -> Dict[str, Any]:
        """ë¬¸ì„œ ìš”ì•½ ìƒì„± - ì¤„ë°”ê¿ˆ ì²˜ë¦¬ ë¬¸ì œ í•´ê²°"""
        try:
            logger.info(f"ğŸ” ìš”ì•½ ìƒì„± ì‹œì‘ - í…ìŠ¤íŠ¸ ê¸¸ì´: {len(content)}")
            logger.info(f"ğŸ“ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {content[:100]}...")

            # í…ìŠ¤íŠ¸ ê¸¸ì´ ê²€ì¦
            if not content or len(content.strip()) < 10:
                raise ValueError("ìš”ì•½í•  í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")

            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì¤„ì„
            if len(content) > 3000:
                logger.warning(f"í…ìŠ¤íŠ¸ê°€ ê¸¸ì–´ì„œ ì¤„ì…ë‹ˆë‹¤: {len(content)} -> 3000ì")
                content = content[:3000] + "..."

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_summary_prompt(content, summary_type, title)
            logger.info(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")

            # Gemini API í˜¸ì¶œ
            response = await self.model.generate_content_async(
                prompt,
                safety_settings=self.safety_settings
            )

            logger.info(f"ğŸ“¨ Gemini ì‘ë‹µ ê¸¸ì´: {len(response.text)}")
            logger.info(f"ğŸ“¨ Gemini ì›ë³¸ ì‘ë‹µ: {response.text}")

            # ì‘ë‹µ ì •ë¦¬ ë° JSON íŒŒì‹±
            clean_text = self._clean_gemini_response(response.text)
            logger.info(f"ğŸ§¹ ì •ë¦¬ëœ ì‘ë‹µ: {clean_text}")

            try:
                parsed_response = json.loads(clean_text)
                logger.info("âœ… JSON íŒŒì‹± ì„±ê³µ!")

                # ì‘ë‹µ ê²€ì¦
                self._validate_summary_response(parsed_response)
                return parsed_response

            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                logger.error(f"âŒ íŒŒì‹± ì‹¤íŒ¨ í…ìŠ¤íŠ¸: {clean_text}")
                return self._create_fallback_summary(content, summary_type, title)

        except Exception as e:
            logger.error(f"âŒ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._create_fallback_summary(content, summary_type, title)

    def _build_summary_prompt(self, content: str, summary_type: str, title: Optional[str] = None) -> str:
        """ê°„ë‹¨í•˜ê³  ì•ˆì „í•œ ìš”ì•½ í”„ë¡¬í”„íŠ¸"""

        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

    í…ìŠ¤íŠ¸: {content}

    ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:

    {{
      "summary": "í•µì‹¬ ë‚´ìš©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½",
      "key_points": ["ìš”ì 1", "ìš”ì 2", "ìš”ì 3"],
      "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"]
    }}

    ì¤‘ìš”ì‚¬í•­:
    - ë§ˆí¬ë‹¤ìš´ ì‚¬ìš© ê¸ˆì§€
    - ì½”ë“œë¸”ë¡ ì‚¬ìš© ê¸ˆì§€  
    - ìˆœìˆ˜ JSONë§Œ ë°˜í™˜
    - ëª¨ë“  ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ì‘ì„±"""

        return prompt

    def _is_response_complete(self, response: Dict[str, Any]) -> bool:
        """ì‘ë‹µì´ ì™„ì „í•œì§€ ê²€ì¦"""
        required_fields = ["summary", "key_points", "keywords"]

        # í•„ìˆ˜ í•„ë“œ ì¡´ì¬ í™•ì¸
        for field in required_fields:
            if field not in response:
                logger.warning(f"ëˆ„ë½ëœ í•„ë“œ: {field}")
                return False

        # summaryê°€ ë„ˆë¬´ ì§§ì§€ ì•Šì€ì§€ í™•ì¸
        if len(response.get("summary", "")) < 20:
            logger.warning("ìš”ì•½ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")
            return False

        # key_pointsê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
        if not isinstance(response.get("key_points"), list):
            logger.warning("key_pointsê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤")
            return False

        return True

    # gemini_service.pyì˜ generate_study_plan ë©”ì„œë“œì— ì¶”ê°€

    def _validate_response_structure(self, response: Dict[str, Any]) -> None:
        """AI ì‘ë‹µ êµ¬ì¡° ê²€ì¦

        Args:
            response: AI ì‘ë‹µ ë°ì´í„°

        Raises:
            ValueError: í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ì‹œ
        """
        required_fields = ["title", "total_weeks", "weekly_plans", "milestones"]
        missing_fields = [field for field in required_fields if field not in response]

        if missing_fields:
            raise ValueError(f"Missing required fields: {missing_fields}")

        # weekly_plans êµ¬ì¡° ê²€ì¦
        if not isinstance(response["weekly_plans"], list):
            raise ValueError("weekly_plans must be a list")

        for i, week_plan in enumerate(response["weekly_plans"]):
            week_required_fields = ["week", "title", "topics", "goals"]
            week_missing_fields = [field for field in week_required_fields if field not in week_plan]

            if week_missing_fields:
                raise ValueError(f"Week {i + 1} missing required fields: {week_missing_fields}")

        # milestones êµ¬ì¡° ê²€ì¦
        if not isinstance(response["milestones"], list):
            raise ValueError("milestones must be a list")

        for i, milestone in enumerate(response["milestones"]):
            milestone_required_fields = ["week", "milestone"]
            milestone_missing_fields = [field for field in milestone_required_fields if field not in milestone]

            if milestone_missing_fields:
                raise ValueError(f"Milestone {i + 1} missing required fields: {milestone_missing_fields}")

    def _clean_gemini_response(self, response_text: str) -> str:
        """Gemini ì‘ë‹µ ì •ë¦¬"""

        logger.info(f"ğŸ” ì›ë³¸ ì‘ë‹µ ê¸¸ì´: {len(response_text)}")

        text = response_text.strip()

        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        if text.startswith("```json") and text.endswith("```"):
            text = text[7:-3].strip()
            logger.info("âœ… ```json``` ë¸”ë¡ ì œê±°")
        elif text.startswith("```") and text.endswith("```"):
            text = text[3:-3].strip()
            logger.info("âœ… ``` ë¸”ë¡ ì œê±°")

        # ì¤‘ê°„ì— ìˆëŠ” ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ë„ ì²˜ë¦¬
        import re
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'\s*```', '', text)

        # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€ê²½ (JSON êµ¬ì¡° ë³´ì¡´)
        text = re.sub(r'\n+', ' ', text)

        # ì—°ì†ëœ ê³µë°± ì •ë¦¬
        text = re.sub(r'\s+', ' ', text)

        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()

        logger.info(f"ğŸ§¹ ì •ë¦¬ í›„ ê¸¸ì´: {len(text)}")

        return text

    def _validate_summary_response(self, response: Dict[str, Any]) -> None:
        """ìš”ì•½ ì‘ë‹µ ê²€ì¦"""
        required_fields = ["summary"]

        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        missing_fields = [field for field in required_fields if field not in response]
        if missing_fields:
            raise ValueError(f"ìš”ì•½ ì‘ë‹µì—ì„œ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {missing_fields}")

        # summary í•„ë“œê°€ ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸
        if not response["summary"] or not response["summary"].strip():
            raise ValueError("ìš”ì•½ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

    def _create_fallback_summary(self, content: str, summary_type: str, title: Optional[str] = None) -> Dict[str, Any]:
        """í´ë°± ìš”ì•½ ìƒì„± - ë²”ìš©ì  ë²„ì „"""

        # ê°„ë‹¨í•œ ë¬¸ì¥ ë¶„ë¦¬
        sentences = content.replace('!', '.').replace('?', '.').split('.')
        clean_sentences = [s.strip() for s in sentences if s.strip() and len(s.strip()) > 10]

        # ì²« 2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ ìƒì„±
        summary_sentences = clean_sentences[:2] if len(clean_sentences) >= 2 else clean_sentences[:1]
        fallback_summary = '. '.join(summary_sentences)

        if not fallback_summary:
            fallback_summary = content[:100].strip()
            if len(content) > 100:
                fallback_summary += "..."

        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
        import re
        words = re.findall(r'[ê°€-í£a-zA-Z0-9]+', content)
        word_freq = {}
        for word in words:
            if len(word) >= 2 and not word.isdigit():
                word_freq[word] = word_freq.get(word, 0) + 1

        # ë¹ˆë„ìˆœ ìƒìœ„ í‚¤ì›Œë“œ
        if word_freq:
            sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
            keywords = [word for word, freq in sorted_words[:5]]
        else:
            keywords = ["ë¬¸ì„œ", "ë‚´ìš©", "ì •ë³´"]

        return {
            "summary": fallback_summary,
            "key_points": [
                "ì£¼ìš” ë‚´ìš© ìš”ì•½",
                "í•µì‹¬ ì •ë³´ ì„¤ëª…",
                "ì¤‘ìš” ì‚¬í•­ ì •ë¦¬"
            ],
            "keywords": keywords[:3],
            "_fallback": True,
            "_reason": "Gemini ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨"
        }

    def _validate_and_fix_response(self, response: Dict[str, Any], original_content: str) -> Dict[str, Any]:
        """ì‘ë‹µ êµ¬ì¡° ê²€ì¦ ë° ìˆ˜ì •"""

        # í•„ìˆ˜ í•„ë“œ í™•ì¸ ë° ë³´ì™„
        if "summary" not in response or not response["summary"]:
            # ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ì²« ë¬¸ì¥ë“¤ë¡œ ìš”ì•½ ìƒì„±
            sentences = original_content.split('.')[:2]
            response["summary"] = '. '.join(s.strip() for s in sentences if s.strip()) + '.'

        if "key_points" not in response or not isinstance(response["key_points"], list):
            response["key_points"] = ["ì£¼ìš” ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨"]

        if "keywords" not in response or not isinstance(response["keywords"], list):
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
            words = original_content.split()
            common_words = ['AWS', 'ê¸°ìˆ ', 'ì„œë¹„ìŠ¤', 'ë°ì´í„°', 'ë¨¸ì‹ ëŸ¬ë‹']
            response["keywords"] = [w for w in common_words if w in original_content][:5]

        if "word_count" not in response:
            response["word_count"] = len(original_content.split())

        if "summary_ratio" not in response:
            summary_len = len(response["summary"].split())
            original_len = len(original_content.split())
            ratio = round((summary_len / original_len) * 100) if original_len > 0 else 0
            response["summary_ratio"] = f"{ratio}%"

        return response


class GeminiServiceConfig:
    """Gemini ì„œë¹„ìŠ¤ ì„¤ì •"""

    # ê¸°ë³¸ ì„¤ì •ê°’
    DEFAULT_TEMPERATURE = 0.7
    DEFAULT_TOP_P = 0.8
    DEFAULT_TOP_K = 40
    DEFAULT_MAX_OUTPUT_TOKENS = 2048

    # ì‘ë‹µ ì‹œê°„ ì œí•œ (ì´ˆ)
    RESPONSE_TIMEOUT = 30

    # ì¬ì‹œë„ ì„¤ì •
    MAX_RETRIES = 3
    RETRY_DELAY = 1  # ì´ˆ